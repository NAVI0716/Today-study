{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fa617d5e",
   "metadata": {},
   "source": [
    "이번 실습에서는 텍스트랭크(TextRank) 알고리즘으로 사용하여 텍스트 요약 방법인 추출적 요약을 진행해보겠습니다.\n",
    "\n",
    "텍스트랭크 알고리즘에 대해서 이해하기 위해서, 텍스트랭크 알고리즘의 기반이 된 페이지랭크 알고리즘에 대해서 간단히 이해해보겠습니다. \n",
    "페이지랭크 알고리즘은 검색 엔진에서 웹 페이지의 순위를 정하기 위해 사용되던 알고리즘입니다. \n",
    "텍스트랭크 알고리즘은 페이지랭크를 기반으로 한 텍스트 요약 알고리즘입니다. 텍스트랭크에서 그래프의 노드들은 문장들이며, 각 간선의 가중치는 문장들 간의 유사도를 의미합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df825052",
   "metadata": {},
   "source": [
    "# 사전 훈련된 임베딩(Pre-trained Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c13b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from urllib.request import urlretrieve, urlopen\n",
    "import gzip\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89f4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 4.26 s, total: 18.3 s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1. 사전 훈련된 GloVe 다운로드 (실습에서 사용)\n",
    "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
    "zf = zipfile.ZipFile('glove.6B.zip')\n",
    "zf.extractall() \n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7b5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = dict()\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")    # 100차원의 GloVe 벡터를 사용\n",
    "\n",
    "for line in f:\n",
    "    word_vector = line.split()\n",
    "    word = word_vector[0]\n",
    "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32') # 100개의 값을 가지는 array로 변환\n",
    "    glove_dict[word] = word_vector_arr\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 사전 훈련된 FastText 다운로드\n",
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300차원의 FastText 벡터 사용\n",
    "import fasttext.util\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96161caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 단어 'cat'에 대한 임베딩 벡터를 얻고싶다면 다음과 같이 얻을 수 있습니다.\n",
    "ft.get_word_vector('cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8332a",
   "metadata": {},
   "source": [
    "# 문장 임베딩(Sentence Embedding)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04754a7f",
   "metadata": {},
   "source": [
    "여러분이 어떤 다수의 문장을 가지고 있다고 해봅시다. 그리고 이 문장들을 서로 비교하고 싶습니다. 만약, 문장들을 각 문장을 표현하는 고정된 길이의 벡터로 변환한다면 벡터 간 비교로 문장을 비교할 수 있을 것입니다. 각 문장을 문장 벡터로 변환하는 방법은 여러가지 방법이 존재하지만, 여기서는 가장 간단한 방법 한 가지를 소개하고자 합니다.\n",
    "\n",
    "문장 벡터를 얻는 가장 간단한 방법은 문장에 존재하는 단어 벡터들의 평균을 구하는 것입니다. 이번 챕터에서는 앞에서 소개한 방법으로 다운로드한 사전 훈련된 임베딩을 사용합니다. 예를 들어 사전 훈련된 GloVe로부터 문장 벡터는 다음과 같이 얻을 수 있습니다.\n",
    "\n",
    "현재 glove_dict에는 100차원의 GloVe 벡터들이 저장되어져 있습니다. OOV 문제. 즉, glove_dict에 존재하지 않는 단어가 문장에 존재할 경우 해당 단어의 임베딩값으로 사용할 100차원의 영벡터도 만들어둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0698e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "zero_vector = np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a9a65ff",
   "metadata": {},
   "source": [
    "아래 함수는 문장의 각 단어를 사전 훈련된 GloVe 벡터로 변환하면서, OOV 문제가 발생할 경우에는 해당 단어를 영벡터로 변환합니다. 그리고 이렇게 모인 단어 벡터들의 평균을 구하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 벡터의 평균으로부터 문장 벡터를 얻는다.\n",
    "def calculate_sentence_vector(sentence):\n",
    "    return sum([glove_dict.get(word, zero_vector) \n",
    "                for word in sentence])/len(sentence)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9b1dd4f",
   "metadata": {},
   "source": [
    "만약 I am a student라는 문장 벡터의 값을 얻고싶다면 해당 문장을 calculate_sentence_vector 함수의 입력으로 사용하면 됩니다. \n",
    "이렇게 반환된 벡터값의 크기는 100차원이 될 것입니다. 여기서는 책의 지면의 한계로 값을 확인하진 않겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sent = ['I', 'am', 'a', 'student']\n",
    "sentence_vector = calculate_sentence_vector(eng_sent)\n",
    "print(len(sentence_vector))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2748c5c7",
   "metadata": {},
   "source": [
    "현재 사용하고 있는 사전 훈련된 GloVe는 영어에 대해서 학습된 임베딩입니다. 그래서 한국어를 넣으면 당연히 모든 단어에 대해서 OOV 문제가 발생합니다. 즉, 모든 단어가 영벡터이므로 평균을 구해도 영벡터가 반환됩니다. 실제로 값을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29e3646",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_sentence_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4152cac2ec9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkor_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'전'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'좋은'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'학생'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'입니다'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentence_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_sentence_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkor_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_sentence_vector' is not defined"
     ]
    }
   ],
   "source": [
    "kor_sent = ['전', '좋은', '학생', '입니다']\n",
    "sentence_vector = calculate_sentence_vector(kor_sent)\n",
    "print(sentence_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a867a3d",
   "metadata": {},
   "source": [
    "# 텍스트 랭크를 이용한 텍스트 요약"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdb94e28",
   "metadata": {},
   "source": [
    "여기서는 앞서 사전 훈련된 GloVe를 다운로드 하였다는 가정 하에 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4810f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831560e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK에서 제공하는 불용어를 받아옵니다.\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e944da52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maria Sharapova has basically no friends as te...</td>\n",
       "      <td>https://www.tennisworldusa.org/tennis/news/Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BASEL, Switzerland (AP), Roger Federer advance...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/copil-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Roger Federer has revealed that organisers of ...</td>\n",
       "      <td>https://scroll.in/field/899938/tennis-roger-fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kei Nishikori will try to end his long losing ...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/nishiko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Federer, 37, first broke through on tour over ...</td>\n",
       "      <td>https://www.express.co.uk/sport/tennis/1036101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                       article_text  \\\n",
       "0           1  Maria Sharapova has basically no friends as te...   \n",
       "1           2  BASEL, Switzerland (AP), Roger Federer advance...   \n",
       "2           3  Roger Federer has revealed that organisers of ...   \n",
       "3           4  Kei Nishikori will try to end his long losing ...   \n",
       "4           5  Federer, 37, first broke through on tour over ...   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.tennisworldusa.org/tennis/news/Mar...  \n",
       "1  http://www.tennis.com/pro-game/2018/10/copil-s...  \n",
       "2  https://scroll.in/field/899938/tennis-roger-fe...  \n",
       "3  http://www.tennis.com/pro-game/2018/10/nishiko...  \n",
       "4  https://www.express.co.uk/sport/tennis/1036101...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 요약에 사용할 테니스 관련 기사를 다운로드하고, 데이터프레임에 저장합니다.\n",
    "urlretrieve(\"https://raw.githubusercontent.com/prateekjoshi565/textrank_text_summarization/master/tennis_articles_v4.csv\", filename=\"tennis_articles_v4.csv\")\n",
    "data = pd.read_csv(\"tennis_articles_v4.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1358d8ff",
   "metadata": {},
   "source": [
    "총 3개의 열이 존재하지만 여기서 사용할 열은 기사 본문에 해당하는 article_text입니다. 해당 article_text열만 사용하기로 하고, 해당 기사를 문장 토큰화한 결과를 저장한 sentences라는 열을 새로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c684ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maria Sharapova has basically no friends as te...</td>\n",
       "      <td>[Maria Sharapova has basically no friends as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BASEL, Switzerland (AP), Roger Federer advance...</td>\n",
       "      <td>[BASEL, Switzerland (AP), Roger Federer advanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roger Federer has revealed that organisers of ...</td>\n",
       "      <td>[Roger Federer has revealed that organisers of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kei Nishikori will try to end his long losing ...</td>\n",
       "      <td>[Kei Nishikori will try to end his long losing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Federer, 37, first broke through on tour over ...</td>\n",
       "      <td>[Federer, 37, first broke through on tour over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadal has not played tennis since he was force...</td>\n",
       "      <td>[Nadal has not played tennis since he was forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tennis giveth, and tennis taketh away. The end...</td>\n",
       "      <td>[Tennis giveth, and tennis taketh away., The e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Federer won the Swiss Indoors last week by bea...</td>\n",
       "      <td>[Federer won the Swiss Indoors last week by be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  Maria Sharapova has basically no friends as te...   \n",
       "1  BASEL, Switzerland (AP), Roger Federer advance...   \n",
       "2  Roger Federer has revealed that organisers of ...   \n",
       "3  Kei Nishikori will try to end his long losing ...   \n",
       "4  Federer, 37, first broke through on tour over ...   \n",
       "5  Nadal has not played tennis since he was force...   \n",
       "6  Tennis giveth, and tennis taketh away. The end...   \n",
       "7  Federer won the Swiss Indoors last week by bea...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [Maria Sharapova has basically no friends as t...  \n",
       "1  [BASEL, Switzerland (AP), Roger Federer advanc...  \n",
       "2  [Roger Federer has revealed that organisers of...  \n",
       "3  [Kei Nishikori will try to end his long losing...  \n",
       "4  [Federer, 37, first broke through on tour over...  \n",
       "5  [Nadal has not played tennis since he was forc...  \n",
       "6  [Tennis giveth, and tennis taketh away., The e...  \n",
       "7  [Federer won the Swiss Indoors last week by be...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['article_text']]\n",
    "data['sentences'] = data['article_text'].apply(sent_tokenize)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3402a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수\n",
    "def tokenization(sentences):\n",
    "    return [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 영어를 제외한 숫자, 특수 문자 등은 전부 제거. 모든 알파벳은 소문자화\n",
    "  sentence = [re.sub(r'[^a-zA-z\\s]', '', word).lower() for word in sentence]\n",
    "  # 불용어가 아니면서 단어가 실제로 존재해야 한다.\n",
    "  return [word for word in sentence if word not in stop_words and word]\n",
    "\n",
    "# 위 전처리 함수를 모든 문장에 대해서 수행. 이 함수를 호출하면 모든 행에 대해서 수행.\n",
    "def preprocess_sentences(sentences):\n",
    "    return [preprocess_sentence(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11499580",
   "metadata": {},
   "source": [
    "문장 토큰화를 진행한 'sentences'열에 대해서 단어 토큰화와 전처리를 적용한 'tokenized_sentences' 열을 새로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8144295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maria Sharapova has basically no friends as te...</td>\n",
       "      <td>[Maria Sharapova has basically no friends as t...</td>\n",
       "      <td>[[maria, sharapova, basically, friends, tennis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BASEL, Switzerland (AP), Roger Federer advance...</td>\n",
       "      <td>[BASEL, Switzerland (AP), Roger Federer advanc...</td>\n",
       "      <td>[[basel, switzerland, ap, roger, federer, adva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roger Federer has revealed that organisers of ...</td>\n",
       "      <td>[Roger Federer has revealed that organisers of...</td>\n",
       "      <td>[[roger, federer, revealed, organisers, relaun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kei Nishikori will try to end his long losing ...</td>\n",
       "      <td>[Kei Nishikori will try to end his long losing...</td>\n",
       "      <td>[[kei, nishikori, try, end, long, losing, stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Federer, 37, first broke through on tour over ...</td>\n",
       "      <td>[Federer, 37, first broke through on tour over...</td>\n",
       "      <td>[[federer, first, broke, tour, two, decades, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadal has not played tennis since he was force...</td>\n",
       "      <td>[Nadal has not played tennis since he was forc...</td>\n",
       "      <td>[[nadal, played, tennis, since, forced, retire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tennis giveth, and tennis taketh away. The end...</td>\n",
       "      <td>[Tennis giveth, and tennis taketh away., The e...</td>\n",
       "      <td>[[tennis, giveth, tennis, taketh, away], [end,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Federer won the Swiss Indoors last week by bea...</td>\n",
       "      <td>[Federer won the Swiss Indoors last week by be...</td>\n",
       "      <td>[[federer, swiss, indoors, last, week, beating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_text  \\\n",
       "0  Maria Sharapova has basically no friends as te...   \n",
       "1  BASEL, Switzerland (AP), Roger Federer advance...   \n",
       "2  Roger Federer has revealed that organisers of ...   \n",
       "3  Kei Nishikori will try to end his long losing ...   \n",
       "4  Federer, 37, first broke through on tour over ...   \n",
       "5  Nadal has not played tennis since he was force...   \n",
       "6  Tennis giveth, and tennis taketh away. The end...   \n",
       "7  Federer won the Swiss Indoors last week by bea...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Maria Sharapova has basically no friends as t...   \n",
       "1  [BASEL, Switzerland (AP), Roger Federer advanc...   \n",
       "2  [Roger Federer has revealed that organisers of...   \n",
       "3  [Kei Nishikori will try to end his long losing...   \n",
       "4  [Federer, 37, first broke through on tour over...   \n",
       "5  [Nadal has not played tennis since he was forc...   \n",
       "6  [Tennis giveth, and tennis taketh away., The e...   \n",
       "7  [Federer won the Swiss Indoors last week by be...   \n",
       "\n",
       "                                 tokenized_sentences  \n",
       "0  [[maria, sharapova, basically, friends, tennis...  \n",
       "1  [[basel, switzerland, ap, roger, federer, adva...  \n",
       "2  [[roger, federer, revealed, organisers, relaun...  \n",
       "3  [[kei, nishikori, try, end, long, losing, stre...  \n",
       "4  [[federer, first, broke, tour, two, decades, a...  \n",
       "5  [[nadal, played, tennis, since, forced, retire...  \n",
       "6  [[tennis, giveth, tennis, taketh, away], [end,...  \n",
       "7  [[federer, swiss, indoors, last, week, beating...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenized_sentences'] = data['sentences'].apply(tokenization)\n",
    "data['tokenized_sentences'] = data['tokenized_sentences'].apply(preprocess_sentences)\n",
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a745991b",
   "metadata": {},
   "source": [
    "현재 사용할 GloVe 벡터의 차원은 100입니다. 100차원의 영벡터를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42cc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "zero_vector = np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65df6cae",
   "metadata": {},
   "source": [
    "단어 벡터의 평균을 구하는 함수를 정의합니다. 단, 문장 길이가 0일 경우에는 100차원의 영벡터를 리턴합니다. 현재 불용어를 제거하였기 때문에 문장의 모든 단어가 불용어인 경우에는 길이가 0인 문장이 생길 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3ecab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 벡터의 평균으로부터 문장 벡터를 얻는다.\n",
    "def calculate_sentence_vector(sentence):\n",
    "    if len(sentence) != 0:\n",
    "        return sum([glove_dict.get(word, zero_vector) \n",
    "                  for word in sentence])/len(sentence)\n",
    "    else:\n",
    "        return zero_vector\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a3e4d72",
   "metadata": {},
   "source": [
    "이를 모든 행에 대해서 수행하기 위해서 모든 문장에 대해서 수행하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "444fed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장에 대해서 문장 벡터를 반환\n",
    "def sentences_to_vectors(sentences):\n",
    "    return [calculate_sentence_vector(sentence) \n",
    "              for sentence in sentences]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dba2670",
   "metadata": {},
   "source": [
    "모든 문장에 대해서 문장 벡터를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fc0663c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceEmbedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.051488996, 0.1105585, 0.6950863, 0.1891917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.10566062456928194, -0.10534465219825506, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.022272188, -0.0474477, 0.14933074, -0.086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.045201838, -0.064647146, 0.5035717, -0.160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.21536233, 0.180915, 0.25600883, 0.06924241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[0.04484453, -0.0074302587, 0.33349112, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[-0.115338005, -0.0062844106, 0.595185, -0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[0.0740439, 0.059211146, 0.49143884, 0.216771...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SentenceEmbedding\n",
       "0  [[0.051488996, 0.1105585, 0.6950863, 0.1891917...\n",
       "1  [[0.10566062456928194, -0.10534465219825506, 0...\n",
       "2  [[-0.022272188, -0.0474477, 0.14933074, -0.086...\n",
       "3  [[0.045201838, -0.064647146, 0.5035717, -0.160...\n",
       "4  [[0.21536233, 0.180915, 0.25600883, 0.06924241...\n",
       "5  [[0.04484453, -0.0074302587, 0.33349112, -0.07...\n",
       "6  [[-0.115338005, -0.0062844106, 0.595185, -0.16...\n",
       "7  [[0.0740439, 0.059211146, 0.49143884, 0.216771..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data['SentenceEmbedding'] = data['tokenized_sentences'].apply(sentences_to_vectors)\n",
    "data[['SentenceEmbedding']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09bd4171",
   "metadata": {},
   "source": [
    "문장 벡터들 간의 코사인 유사도를 구한 유사도 행렬을 만듭니다. 이 유사도 행렬의 크기는 (문장 개수 × 문장 개수)입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a222de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(sentence_embedding):\n",
    "    sim_mat = np.zeros([len(sentence_embedding), len(sentence_embedding)])\n",
    "    for i in range(len(sentence_embedding)):\n",
    "        for j in range(len(sentence_embedding)):\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_embedding[i].reshape(1, embedding_dim),\n",
    "                                          sentence_embedding[j].reshape(1, embedding_dim))[0,0]\n",
    "    return sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee009a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 결과를 저장한 'SimMatrix'열을 만듭니다.\n",
    "data['SimMatrix'] = data['SentenceEmbedding'].apply(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad731137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[1.0, 0.6477208137512207, 0.5915699601173401,...\n",
       "1    [[1.0000000000000002, 0.8745531210608369, 0.80...\n",
       "2    [[0.9999998807907104, 0.913085401058197, 0.899...\n",
       "3    [[0.9999999403953552, 0.7769179305294039, 0.84...\n",
       "4    [[0.9999999403953552, 0.8306209732530097, 0.90...\n",
       "5    [[1.0, 0.8843014240264893, 0.8540289072721128,...\n",
       "6    [[1.0, 0.473054975271225, 0.45002683997154236,...\n",
       "7    [[1.0000001192092896, 0.7634095600081803, 0.78...\n",
       "Name: SimMatrix, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SimMatrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3e5c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두번째 샘플의 문장 개수 : 12\n",
      "두번째 샘플의 문장 벡터가 모인 문장 행렬의 크기(shape) : (12, 100)\n",
      "두번째 샘플의 유사도 행렬의 크기(shape) : (12, 12)\n"
     ]
    }
   ],
   "source": [
    "# 두번째 샘플을 기준으로 지금까지 만든 열들의 크기를 확인해봅시다.\n",
    "print('두번째 샘플의 문장 개수 :',len(data['tokenized_sentences'][1]))\n",
    "print('두번째 샘플의 문장 벡터가 모인 문장 행렬의 크기(shape) :',np.shape(data['SentenceEmbedding'][1]))\n",
    "print('두번째 샘플의 유사도 행렬의 크기(shape) :',data['SimMatrix'][1].shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8746c9da",
   "metadata": {},
   "source": [
    "두번째 샘플의 경우에는 총 문장이 12개가 존재합니다. 그래서 문장 벡터 또한 12개가 존재하며, 각 문장 벡터는 100의 크기를 가집니다. 유사도 행렬은 각 문장 벡터들의 유사도가 기록된 유사도 행렬이므로 (문장 개수 × 문장 개수)의 크기를 가집니다.\n",
    "\n",
    "주어진 유사도 행렬로부터 그래프를 그려봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aa84206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graphs(sim_matrix):\n",
    "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(nx_graph)\n",
    "    nx.draw(nx_graph, with_labels=True, font_weight='bold')\n",
    "    nx.draw_networkx_edge_labels(nx_graph,pos,font_color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c76ece1",
   "metadata": {},
   "source": [
    "두번째 샘플의 유사도 행렬로부터 그린 그래프는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d793ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graphs(data['SimMatrix'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820401e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3dd5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e5ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3a7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b5282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f657e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19964e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14066a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbec5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9d8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
