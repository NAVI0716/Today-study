{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064e6bac",
   "metadata": {},
   "source": [
    "## 자연어 전처리-한글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1244f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bef5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('ratings_train.txt')[['document','label']]\n",
    "test_data = pd.read_table('ratings_test.txt')[['document','label']]\n",
    "data=pd.concat((train_data,test_data),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc68c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=data.rename(columns = {'label':'y', 'document' : 'X'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c940c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_w=set(['은','는','이','가','를','들','에게','의','을','도','으로','만','라서','하다'])\n",
    "#s_w.add(불용어 추가문자열)\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9de05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d196d1df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194543, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].nunique(), data['y'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14674e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_13056/3039578657.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X']=data.X.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','')\n",
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_13056/3039578657.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X']=data.clean_X.str.replace('^ +','')\n"
     ]
    }
   ],
   "source": [
    "data=data.drop_duplicates(subset=['X'])\n",
    "data['clean_X']=data.X.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','') \n",
    "data['clean_X']=data.clean_X.str.replace('^ +','')\n",
    "data['clean_X']=data.clean_X.replace('',np.nan) \n",
    "data=data.dropna(how='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90bb317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 193518/193518 [05:06<00:00, 631.22it/s]\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "from tqdm import tqdm \n",
    "X_data=[] \n",
    "for i in tqdm(data['clean_X']): \n",
    "    tk_d=okt.morphs(i) \n",
    "    end_d=[w for w in tk_d if not w in s_w] \n",
    "    X_data.append(' '.join(end_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5aa3ef8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['y_name']=data['y']\n",
    "data['encoder_y']=LabelEncoder().fit_transform(data['y'])\n",
    "data['categorical_y']=list(to_categorical(data['encoder_y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2221e",
   "metadata": {},
   "source": [
    "정규표현식 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126fc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['encoder_y']\n",
    "#Y=to_categorical(data['encoder_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c737ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea13f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data,test_x,y_data,test_y = train_test_split(X,Y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58048d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,val_x,train_y,val_y = train_test_split(x_data,y_data,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b635c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer() \n",
    "tk.fit_on_texts(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb7459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len([d for d in sorted(list(tk.word_counts.items()),key=lambda x:x[1]) if d[1]>4])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52c066f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token=Tokenizer(n)\n",
    "token.fit_on_texts(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75d73644",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_train_x=token.texts_to_sequences(train_x)\n",
    "token_test_x=token.texts_to_sequences(test_x)\n",
    "token_val_x=token.texts_to_sequences(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cfc6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = pad_sequences(token_train_x)\n",
    "test_inputs = pad_sequences(token_test_x)\n",
    "val_inputs = pad_sequences(token_val_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
