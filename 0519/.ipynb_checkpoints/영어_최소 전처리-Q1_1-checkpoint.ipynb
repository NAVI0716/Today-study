{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064e6bac",
   "metadata": {},
   "source": [
    "## 자연어 전처리-영어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454d4e1",
   "metadata": {},
   "source": [
    "관련 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1244f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer #전처리 : 토큰화\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # 시퀸스 패딩이지만 정확한 용도 ????????????????\n",
    "from sklearn.preprocessing import LabelEncoder # ????\n",
    "from sklearn.model_selection import train_test_split # 테스트모델과 트레이닝 모델 생성\n",
    "from tensorflow.keras.utils import to_categorical #y.shape 변형하는데 사용했지만 정확한 용도는 ??????????????? \n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords # 불용어처리\n",
    "from bs4 import BeautifulSoup #html 파서 ??????\n",
    "import re #???????????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ad5b8",
   "metadata": {},
   "source": [
    "전처리 메소드 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae36b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X_text, remove_stopwords=False):\n",
    "    X_text = BeautifulSoup(X_text, 'lxml').get_text()#문서에서 단어를 가져옴\n",
    "    X_text = re.sub(\"[^a-zA-Z]\", \" \", X_text) # 영어 소문자에서 대문자 제외하고 전부 공백처리???????\n",
    "    words = X_text.lower().split()#x데이터 소문자화 공백구분\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words('english'))#영어 불용어 단어 리스트\n",
    "        #stops.add(불용어 문자열)\n",
    "        words = [w for w in words if not w in stops]#불용어가 없으면 리스트 등록\n",
    "        clean_text = ' '.join(words)#등록된 리스트 목록을 공백기준으로 병합\n",
    "    else:\n",
    "        clean_text = ' '.join(words)\n",
    "        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d26f73",
   "metadata": {},
   "source": [
    "data불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc68c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('spam.csv',encoding='latin1')[['v1','v2']]#데이터 v1과 v2를 불러옴\n",
    "data=data.rename(columns = {'v1':'y', 'v2' : 'X'}) # 데이터 이름변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebf7fa",
   "metadata": {},
   "source": [
    "불용어처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52695bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_X']=data['X'].apply(lambda x : preprocessing(X_text=x, remove_stopwords=True))\n",
    "#불러온 data의 x값을위의 전처리험수를 사용해 불용어 소문자 영어단어만 블러와준다.\n",
    "#data['X'].apply이부분은 무슨 용도인지 ???????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5993d6fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['y_name']=data['y']\n",
    "data['encoder_y']=LabelEncoder().fit_transform(data['y'])# LabelEncoder()?????????\n",
    "data['categorical_y']=list(to_categorical(data['encoder_y']))#y.shape 변형하는데 사용했지만 정확한 용도는????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9de05a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any() #data파일에 공백 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d196d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_X'].nunique(), data['y'].nunique() # 값중 서로다른값이 몇개인지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610dda41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_7268/835016061.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X'] = data['clean_X'].str.replace(\"[^a-zA-Z0-9 ]\",\"\")\n",
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_7268/835016061.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X'] = data['clean_X'].str.replace('^ +', \"\")\n"
     ]
    }
   ],
   "source": [
    "data['clean_X'] = data['clean_X'].str.replace(\"[^a-zA-Z0-9 ]\",\"\")#영대문자,숫자,공백 제외한 문자는 공백처리\n",
    "data['clean_X'] = data['clean_X'].str.replace('^ +', \"\")#문장 첫단 공백제거\n",
    "data['clean_X'].replace('', np.nan, inplace=True)#공백을 nan으로 변경\n",
    "data = data.dropna(how = 'any')#nan값의 줄을 빼낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2360bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['encoder_y']#y데이터지정\n",
    "#Y=to_categorical(data['encoder_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da06721",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['clean_X']#x데이터지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ca838",
   "metadata": {},
   "source": [
    "train_test 나눌때 x->x_data로 나눈것들 다시 train,val로 나눠서 쓰는구나는 알겠는데 나누는 규칙이나 방법은 잘모르겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3413d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data,test_x,y_data,test_y = train_test_split(X,Y,test_size=0.3,random_state=0)#x,y데이터와 테스트데이터 비율 7:3,랜덤값 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aca3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,val_x,train_y,val_y = train_test_split(x_data,y_data,test_size=0.2,random_state=0)#트레이닝데이터와 검증데이터 비율 8:2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c066f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token=Tokenizer()#토큰단어클래스 불러옴\n",
    "token.fit_on_texts(train_x)#train_x 단어들을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d09b4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len([d for d in sorted(list(tk.word_counts.items()),key=lambda x:x[1]) if d[1]>4])+1\n",
    "#tk.word_counts, 각 단어들이 얼만큼 사용된었는지 빈도수를 카운트 (단어,빈도수), 빈도수가 4초과이면 리스트추가+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c89e337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer(n)#num_words=n으로 단어를 한정시켜줌\n",
    "token.fit_on_texts(train_x)#n으로 한정된단어를 학습 이때에 공백이 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650e0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_train_x=token.texts_to_sequences(train_x)## 시퀸스화라고하는데 정확한 용도??????????? 인덱스 숫자화??\n",
    "token_test_x=token.texts_to_sequences(test_x)## 시퀸스화라고하는데 정확한 용도???????????\n",
    "token_val_x=token.texts_to_sequences(val_x)## 시퀸스화라고하는데 정확한 용도???????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "498182e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#공백 리스트 목록 생성\n",
    "drop_train = [index for index, sentence in enumerate(token_train_x) if len(sentence) < 1]\n",
    "drop_test = [index for index, sentence in enumerate(token_test_x) if len(sentence) < 1]\n",
    "drop_val = [index for index, sentence in enumerate(token_val_x) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "462e0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#공백 리스트로 공백 제거\n",
    "token_train_x = np.delete(token_train_x, drop_train, axis=0)\n",
    "train_y = np.delete(train_y, drop_train, axis=0)\n",
    "token_test_x = np.delete(token_test_x, drop_test, axis=0)\n",
    "test_y = np.delete(test_y, drop_test, axis=0)\n",
    "token_val_x = np.delete(token_val_x, drop_val, axis=0)\n",
    "val_y = np.delete(val_y, drop_val, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a995228",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_l=len(pad_sequences(token_train_x)[0])#n-1 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55f59d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = pad_sequences(token_train_x)#패딩작업 큰값에 맞춰 나머지 빈값들 0으로 채워줌\n",
    "test_inputs = pad_sequences(token_test_x)\n",
    "val_inputs = pad_sequences(token_val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be0369d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs=train_y\n",
    "test_outputs=test_y\n",
    "val_outputs=val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda0e775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((3071, 50), (3071,)), ((1640, 50), (1640,)), ((756, 50), (756,)))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_inputs.shape,train_outputs.shape),(test_inputs.shape,test_outputs.shape),(val_inputs.shape,val_outputs.shape)\n",
    "#학습 검증 테스트 모양확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
